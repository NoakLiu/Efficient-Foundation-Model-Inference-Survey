# Efficient-Large-Foundation-Model-Inference-A-Perspective-From-Model-and-System-Co-Design
Paper Link: https://arxiv.org/abs/2409.01990

## Model Design
### Quantization
### Distillation
### Pruning

## System Design
### K-V Cache
### Cache Eviction
### Parallism
### Sparsity
### Memory Management
### MoE

## Model-Sys Co-Design
### Mixed Precision Training
### Fine Tuning with System Optimization
